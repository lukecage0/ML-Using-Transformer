{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2901391,"sourceType":"datasetVersion","datasetId":1201455},{"sourceId":7659566,"sourceType":"datasetVersion","datasetId":4466017},{"sourceId":7603362,"sourceType":"datasetVersion","datasetId":4426427}],"dockerImageVersionId":30068,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RDKit\n\n* The following command installs the RDKit library using pip.\n* RDKit is a cheminformatics software library widely used in molecular modeling and drug discovery projects.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Install RDKit library using pip\n!pip install rdkit ","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:56:38.452714Z","iopub.execute_input":"2024-02-19T23:56:38.453053Z","iopub.status.idle":"2024-02-19T23:56:48.615090Z","shell.execute_reply.started":"2024-02-19T23:56:38.452962Z","shell.execute_reply":"2024-02-19T23:56:48.614112Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting rdkit\n  Downloading rdkit-2023.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.5 MB)\n\u001b[K     |████████████████████████████████| 29.5 MB 12.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rdkit) (1.19.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from rdkit) (7.2.0)\nInstalling collected packages: rdkit\nSuccessfully installed rdkit-2023.3.2\n\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Bunch:\n* The following command installs the Bunch library using pip.\n* Bunch is a lightweight Python module that provides a dictionary-like object with attribute-style access.\n","metadata":{}},{"cell_type":"code","source":"!pip install bunch","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:56:58.494512Z","iopub.execute_input":"2024-02-19T23:56:58.494842Z","iopub.status.idle":"2024-02-19T23:57:07.077245Z","shell.execute_reply.started":"2024-02-19T23:56:58.494815Z","shell.execute_reply":"2024-02-19T23:57:07.076359Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bunch\n  Downloading bunch-1.0.1.zip (11 kB)\nBuilding wheels for collected packages: bunch\n  Building wheel for bunch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bunch: filename=bunch-1.0.1-py3-none-any.whl size=7074 sha256=1e1a79ca342be34ebbc728cdcb9fcb098396c80de5173aa79b8c866d52a712fd\n  Stored in directory: /root/.cache/pip/wheels/10/ad/12/a8818fda74a365129e0f316c41a12dead904b60534d2114448\nSuccessfully built bunch\nInstalling collected packages: bunch\nSuccessfully installed bunch-1.0.1\n\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing pandas library for data manipulation\nimport pandas as pd\n\n# Importing Chem module from RDKit for molecular chemistry operations\nfrom rdkit import Chem, DataStructs\n\n# Importing random module for generating random numbers\nimport random\n\n# Importing numpy library for numerical operations\nimport numpy as np\n\n# Importing PropertyMol and Descriptors modules from RDKit for molecular property calculations\nimport rdkit.Chem.PropertyMol\nimport rdkit.Chem.Descriptors\n\n# Importing json module for working with JSON data\nimport json\n\n# Importing time module for time-related operations\nimport time\n\n# Importing Bunch module for creating dictionary-like objects with attribute-style access\nfrom bunch import Bunch\n\n# Importing os module for interacting with the operating system\nimport os\n\n# Importing tqdm module for displaying progress bars during iterations\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.080042Z","iopub.execute_input":"2024-02-19T23:57:07.080465Z","iopub.status.idle":"2024-02-19T23:57:07.223999Z","shell.execute_reply.started":"2024-02-19T23:57:07.080423Z","shell.execute_reply":"2024-02-19T23:57:07.223238Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Global variable indicating the generation number\nGLOBAL_GENERATION = 3","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.225206Z","iopub.execute_input":"2024-02-19T23:57:07.225637Z","iopub.status.idle":"2024-02-19T23:57:07.228986Z","shell.execute_reply.started":"2024-02-19T23:57:07.225600Z","shell.execute_reply":"2024-02-19T23:57:07.228183Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Importing pandas library for data manipulation\nimport pandas as pd\n\n# Reading the master results table from a CSV file\nmaster_table = pd.read_csv('../input/generation/master_results_table' + '.csv', sep=',')\n\n# Displaying the last few rows of the master table\nmaster_table.tail()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.230080Z","iopub.execute_input":"2024-02-19T23:57:07.230363Z","iopub.status.idle":"2024-02-19T23:57:07.272772Z","shell.execute_reply.started":"2024-02-19T23:57:07.230336Z","shell.execute_reply":"2024-02-19T23:57:07.271872Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  smile  gen    id  source  \\\n1126  CCCC1(CCc2ccccc2)CC(O)=C(C(CC)c2cccc(NS(=O)(=O...    0  ABRH  manual   \n1127           O=C1Nc2ccc(Cl)cc2C(C#CC2CC2)(C(F)(F)F)O1    0  ABRI  manual   \n1128  CC(C)(C)NC(=O)C1CN(Cc2cccnc2)CCN1CC(O)CC(Cc1cc...    0  ABRJ  manual   \n1129  CCOP(=O)(COc1ccc(CC(NC(=O)OC2COC3OCCC23)C(O)CN...    0  ABRK  manual   \n1130  COC(=O)NC(C(=O)NCCCCC(CO)N(CC(C)C)S(=O)(=O)c1c...    0  ABRL  manual   \n\n      weight  score_best  score_avg  similarity_to_hiv_inhibitors  \\\n1126     NaN         NaN        NaN                           NaN   \n1127     NaN         NaN        NaN                           NaN   \n1128     NaN         NaN        NaN                           NaN   \n1129     NaN         NaN        NaN                           NaN   \n1130     NaN         NaN        NaN                           NaN   \n\n      similarity_to_remdesivir  score  \n1126                       NaN   99.9  \n1127                       NaN   99.9  \n1128                       NaN   99.9  \n1129                       NaN   99.9  \n1130                       NaN   99.9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smile</th>\n      <th>gen</th>\n      <th>id</th>\n      <th>source</th>\n      <th>weight</th>\n      <th>score_best</th>\n      <th>score_avg</th>\n      <th>similarity_to_hiv_inhibitors</th>\n      <th>similarity_to_remdesivir</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1126</th>\n      <td>CCCC1(CCc2ccccc2)CC(O)=C(C(CC)c2cccc(NS(=O)(=O...</td>\n      <td>0</td>\n      <td>ABRH</td>\n      <td>manual</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>1127</th>\n      <td>O=C1Nc2ccc(Cl)cc2C(C#CC2CC2)(C(F)(F)F)O1</td>\n      <td>0</td>\n      <td>ABRI</td>\n      <td>manual</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>1128</th>\n      <td>CC(C)(C)NC(=O)C1CN(Cc2cccnc2)CCN1CC(O)CC(Cc1cc...</td>\n      <td>0</td>\n      <td>ABRJ</td>\n      <td>manual</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>1129</th>\n      <td>CCOP(=O)(COc1ccc(CC(NC(=O)OC2COC3OCCC23)C(O)CN...</td>\n      <td>0</td>\n      <td>ABRK</td>\n      <td>manual</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>COC(=O)NC(C(=O)NCCCCC(CO)N(CC(C)C)S(=O)(=O)c1c...</td>\n      <td>0</td>\n      <td>ABRL</td>\n      <td>manual</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Importing pandas library for data manipulation\nimport pandas as pd\n\n# Reading a new set of scores from a CSV file\nnew_scores = pd.read_csv('../input/generation/mergededited.csv', sep=',')\n\n# Displaying the first few rows of the new scores DataFrame\nnew_scores.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.275196Z","iopub.execute_input":"2024-02-19T23:57:07.275485Z","iopub.status.idle":"2024-02-19T23:57:07.307688Z","shell.execute_reply.started":"2024-02-19T23:57:07.275459Z","shell.execute_reply":"2024-02-19T23:57:07.306740Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                   Ligand  Binding Affinity  rmsd/ub   rmsd/lb\n0  7act_model1_idAFRXgen2              -8.2    0.000     0.000\n1  7act_model1_idAFRXgen2              -8.1    2.429     1.724\n2  7act_model1_idAAZSgen2              -8.1    0.000     0.000\n3  7act_model1_idACVVgen2              -8.0    0.000     0.000\n4  7act_model1_idAFRMgen2              -7.9    0.000     0.000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ligand</th>\n      <th>Binding Affinity</th>\n      <th>rmsd/ub</th>\n      <th>rmsd/lb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7act_model1_idAFRXgen2</td>\n      <td>-8.2</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7act_model1_idAFRXgen2</td>\n      <td>-8.1</td>\n      <td>2.429</td>\n      <td>1.724</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7act_model1_idAAZSgen2</td>\n      <td>-8.1</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7act_model1_idACVVgen2</td>\n      <td>-8.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7act_model1_idAFRMgen2</td>\n      <td>-7.9</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Grouping the new_scores DataFrame by 'Ligand' and calculating the minimum value of 'Binding Affinity' for each group\n# Explanation:\n# - Grouping by 'Ligand' ensures that each ligand is treated as a separate group.\n# - The minimum 'Binding Affinity' value for each ligand group is calculated.\n# - The result is stored as a DataFrame with 'Ligand' as the index and the minimum 'Binding Affinity' as the only column.\nnew_scores = new_scores.groupby(\"Ligand\").min()[\"Binding Affinity\"].reset_index()\n\n# Extracting 'id' from the 'Ligand' column\n# Explanation:\n# - 'Ligand' column contains strings with a specific format, e.g., 'some_text_idX_genY'.\n# - Extracting 'id' involves splitting the string by '_' and extracting the element after 'id'.\n# - The result is stored in a new column named 'id'.\nnew_scores['id'] = new_scores['Ligand'].str.split(\"_\").str[2].str.split(\"gen\").str[0].str.split(\"id\").str[1]\n\n# Extracting 'gen' from the 'Ligand' column\n# Explanation:\n# - Similar to extracting 'id', extracting 'gen' involves splitting the string by '_' and extracting the element after 'gen'.\n# - The result is stored in a new column named 'gen'.\nnew_scores['gen'] = new_scores['Ligand'].str.split(\"_\").str[2].str.split(\"gen\").str[1]\n\n# Renaming and reordering columns\n# Explanation:\n# - Renaming the 'Binding Affinity' column to 'score' to make it more descriptive.\n# - Reordering columns to have 'id', 'gen', and 'score' as the first, second, and third columns, respectively.\nnew_scores['score'] = new_scores[\"Binding Affinity\"]\nnew_scores = new_scores[['id', 'gen', 'score']]\n\n# Displaying the first few rows of the modified new_scores DataFrame\nnew_scores.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.309124Z","iopub.execute_input":"2024-02-19T23:57:07.309481Z","iopub.status.idle":"2024-02-19T23:57:07.347938Z","shell.execute_reply.started":"2024-02-19T23:57:07.309444Z","shell.execute_reply":"2024-02-19T23:57:07.347212Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"     id gen  score\n0  AAZD   2   -5.2\n1  AAZE   2   -5.5\n2  AAZF   2   -5.4\n3  AAZG   2   -6.8\n4  AAZH   2   -5.6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gen</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAZD</td>\n      <td>2</td>\n      <td>-5.2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAZE</td>\n      <td>2</td>\n      <td>-5.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAZF</td>\n      <td>2</td>\n      <td>-5.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAZG</td>\n      <td>2</td>\n      <td>-6.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAZH</td>\n      <td>2</td>\n      <td>-5.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Converting 'id' column in new_scores DataFrame to string type\n# This step ensures consistency in data type for 'id' column.\nnew_scores.id = new_scores.id.astype(str)\n\n# Converting 'gen' column in new_scores DataFrame to integer type\n# This step ensures consistency in data type for 'gen' column.\nnew_scores.gen = new_scores.gen.astype(int)\n\n# Converting 'id' column and 'gen' column in master_table DataFrame to string and integer types, respectively\n# These steps ensure consistency in data types for 'id' and 'gen' columns in master_table.\nmaster_table.id = master_table.id.astype(str)\nmaster_table.gen = master_table.gen.astype(int)\n\n# Merging master_table and new_scores DataFrames based on 'id' and 'gen' columns\n# The merge is performed using 'id' and 'gen' columns as the joining keys.\n# The suffixes '_old' and '_new' are added to distinguish columns from the original and new DataFrames.\n# Left join is used to retain all rows from the master_table DataFrame.\nnew_table = pd.merge(master_table, new_scores, on=['id', 'gen'], suffixes=('_old', '_new'), how='left')\n\n# Updating 'score' column in new_table DataFrame based on conditions\n# If 'score_new' is null, 'score_old' is used; otherwise, 'score_new' is used.\n# This step ensures that the 'score' column contains updated values from new_scores DataFrame if available.\nnew_table['score'] = np.where(new_table['score_new'].isnull(), new_table['score_old'], new_table['score_new'])\n\n# Dropping 'score_old' and 'score_new' columns from new_table DataFrame\n# These columns are dropped as they are no longer needed after updating the 'score' column.\nnew_table = new_table.drop(['score_old', 'score_new'], axis=1)\n\n# Calculating molecular weight ('weight') based on SMILES representation\n# Molecular weight is calculated using RDKit's MolWt function applied to each SMILES string.\nnew_table['weight'] = new_table['smile'].apply(lambda x: rdkit.Chem.Descriptors.MolWt(Chem.MolFromSmiles(x)))\n\n# Sorting new_table DataFrame based on 'score' column in ascending order\n# This step sorts the DataFrame based on the calculated 'score' values.\nnew_table = new_table.sort_values('score', ascending=True)\n\n# Displaying the first few rows of the modified new_table DataFrame\nnew_table.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.349232Z","iopub.execute_input":"2024-02-19T23:57:07.349526Z","iopub.status.idle":"2024-02-19T23:57:07.556894Z","shell.execute_reply.started":"2024-02-19T23:57:07.349499Z","shell.execute_reply":"2024-02-19T23:57:07.555926Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                 smile  gen    id     source  \\\n1        C#Cc1cccc(Nc2ncnc3c2c(C(C)(C)C)c(C)n3CCC#N)c1    0  AAAA  generated   \n744    CN(C)CCC(CCNC(=O)Oc1ccccc1)(Cc1ccccc1)NC1CCCCC1    0  ABCP  generated   \n745               Cc1csc(SCC(=O)Nc2ccc(OC3CCCC3)nc2)n1    0  ABCQ  generated   \n746               CC1(C)Cc2cccc(C(C#N)NC(=O)C3CC3)c2C1    0  ABCR  generated   \n747  CC(C(=O)Nc1ccccc1N1CCCC1)n1nc(C(F)(F)F)cc1C(F)...    0  ABCS  generated   \n\n      weight  score_best  score_avg  similarity_to_hiv_inhibitors  \\\n1    357.461         NaN        NaN                           NaN   \n744  437.628         NaN        NaN                           NaN   \n745  349.481         NaN        NaN                           NaN   \n746  268.360         NaN        NaN                           NaN   \n747  420.357         NaN        NaN                           NaN   \n\n     similarity_to_remdesivir  score  \n1                         NaN   99.9  \n744                       NaN   99.9  \n745                       NaN   99.9  \n746                       NaN   99.9  \n747                       NaN   99.9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smile</th>\n      <th>gen</th>\n      <th>id</th>\n      <th>source</th>\n      <th>weight</th>\n      <th>score_best</th>\n      <th>score_avg</th>\n      <th>similarity_to_hiv_inhibitors</th>\n      <th>similarity_to_remdesivir</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>C#Cc1cccc(Nc2ncnc3c2c(C(C)(C)C)c(C)n3CCC#N)c1</td>\n      <td>0</td>\n      <td>AAAA</td>\n      <td>generated</td>\n      <td>357.461</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>CN(C)CCC(CCNC(=O)Oc1ccccc1)(Cc1ccccc1)NC1CCCCC1</td>\n      <td>0</td>\n      <td>ABCP</td>\n      <td>generated</td>\n      <td>437.628</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>Cc1csc(SCC(=O)Nc2ccc(OC3CCCC3)nc2)n1</td>\n      <td>0</td>\n      <td>ABCQ</td>\n      <td>generated</td>\n      <td>349.481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>746</th>\n      <td>CC1(C)Cc2cccc(C(C#N)NC(=O)C3CC3)c2C1</td>\n      <td>0</td>\n      <td>ABCR</td>\n      <td>generated</td>\n      <td>268.360</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>747</th>\n      <td>CC(C(=O)Nc1ccccc1N1CCCC1)n1nc(C(F)(F)F)cc1C(F)...</td>\n      <td>0</td>\n      <td>ABCS</td>\n      <td>generated</td>\n      <td>420.357</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save new_table to a CSV file with generation number in the filename\nnew_table.to_csv(r'master_results_table_gen' + str(GLOBAL_GENERATION - 1) + '.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.558158Z","iopub.execute_input":"2024-02-19T23:57:07.558458Z","iopub.status.idle":"2024-02-19T23:57:07.816354Z","shell.execute_reply.started":"2024-02-19T23:57:07.558430Z","shell.execute_reply":"2024-02-19T23:57:07.815648Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Extract top 35 unique SMILES strings for training\ntraining_smiles = list(set(list(new_table.head(35)['smile'])))\n# Check the number of unique SMILES extracted for training\nlen(training_smiles)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.817628Z","iopub.execute_input":"2024-02-19T23:57:07.817940Z","iopub.status.idle":"2024-02-19T23:57:07.825470Z","shell.execute_reply.started":"2024-02-19T23:57:07.817911Z","shell.execute_reply":"2024-02-19T23:57:07.824584Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"35"},"metadata":{}}]},{"cell_type":"code","source":"# Generate fingerprints for each SMILES string in the training set\ntraining_fingerprints = []\nfor smile in training_smiles:\n    training_fingerprints.append(Chem.RDKFingerprint(Chem.MolFromSmiles(smile)))\n\n# Function to calculate similarity-adjusted score for each row in new_table\ndef calc_similarity_score(row):\n    # Generate fingerprint for the current row's SMILES string\n    fingerprint = Chem.RDKFingerprint(Chem.MolFromSmiles(row['smile']))\n    # Calculate Tanimoto similarity between the current fingerprint and all training fingerprints,\n    # then adjust the score based on the highest similarity\n    similarity = np.max(DataStructs.BulkTanimotoSimilarity(fingerprint, training_fingerprints))\n    adj_factor = (1 / similarity) ** 0.333\n    adj_score = row['score'] * adj_factor\n    return adj_score\n\n# Create a deep copy of new_table and filter out rows with molecular weight greater than 900\nsimilarity_adjusted = new_table.copy(deep=True)\nsimilarity_adjusted = similarity_adjusted[similarity_adjusted['weight'] < 900]\n\n# Apply calc_similarity_score function to calculate similarity-adjusted score for each row\nsimilarity_adjusted['similarity_adj_score'] = similarity_adjusted.apply(calc_similarity_score, axis=1)\n\n# Sort the similarity-adjusted DataFrame by 'similarity_adj_score' in ascending order\nsimilarity_adjusted = similarity_adjusted.sort_values('similarity_adj_score', ascending=True)\n\n# Display the first few rows of the similarity-adjusted DataFrame\nsimilarity_adjusted.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:07.826650Z","iopub.execute_input":"2024-02-19T23:57:07.826901Z","iopub.status.idle":"2024-02-19T23:57:09.451814Z","shell.execute_reply.started":"2024-02-19T23:57:07.826873Z","shell.execute_reply":"2024-02-19T23:57:09.450941Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             smile  gen    id     source  \\\n1    C#Cc1cccc(Nc2ncnc3c2c(C(C)(C)C)c(C)n3CCC#N)c1    0  AAAA  generated   \n772         COc1ccc(-c2cc(-c3ncc(C)o3)c(N)o2)cc1OC    0  ABDR  generated   \n771         Cc1cccn2cc(S(=O)(=O)N(C)Cc3ccccc3)nc12    0  ABDQ  generated   \n770             CCc1noc(CC)c1CNC(=O)c1ccc(C)c(N)c1    0  ABDP  generated   \n769          CC(=O)Nc1ccc(OC(=O)c2cc(C)n(C)c2C)cc1    0  ABDO  generated   \n\n      weight  score_best  score_avg  similarity_to_hiv_inhibitors  \\\n1    357.461         NaN        NaN                           NaN   \n772  300.314         NaN        NaN                           NaN   \n771  315.398         NaN        NaN                           NaN   \n770  287.363         NaN        NaN                           NaN   \n769  286.331         NaN        NaN                           NaN   \n\n     similarity_to_remdesivir  score  similarity_adj_score  \n1                         NaN   99.9                  99.9  \n772                       NaN   99.9                  99.9  \n771                       NaN   99.9                  99.9  \n770                       NaN   99.9                  99.9  \n769                       NaN   99.9                  99.9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smile</th>\n      <th>gen</th>\n      <th>id</th>\n      <th>source</th>\n      <th>weight</th>\n      <th>score_best</th>\n      <th>score_avg</th>\n      <th>similarity_to_hiv_inhibitors</th>\n      <th>similarity_to_remdesivir</th>\n      <th>score</th>\n      <th>similarity_adj_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>C#Cc1cccc(Nc2ncnc3c2c(C(C)(C)C)c(C)n3CCC#N)c1</td>\n      <td>0</td>\n      <td>AAAA</td>\n      <td>generated</td>\n      <td>357.461</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>772</th>\n      <td>COc1ccc(-c2cc(-c3ncc(C)o3)c(N)o2)cc1OC</td>\n      <td>0</td>\n      <td>ABDR</td>\n      <td>generated</td>\n      <td>300.314</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>Cc1cccn2cc(S(=O)(=O)N(C)Cc3ccccc3)nc12</td>\n      <td>0</td>\n      <td>ABDQ</td>\n      <td>generated</td>\n      <td>315.398</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>770</th>\n      <td>CCc1noc(CC)c1CNC(=O)c1ccc(C)c(N)c1</td>\n      <td>0</td>\n      <td>ABDP</td>\n      <td>generated</td>\n      <td>287.363</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>CC(=O)Nc1ccc(OC(=O)c2cc(C)n(C)c2C)cc1</td>\n      <td>0</td>\n      <td>ABDO</td>\n      <td>generated</td>\n      <td>286.331</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>99.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Add top 5 SMILES strings from similarity_adjusted to training_smiles\ntraining_smiles += list(similarity_adjusted.head(5)['smile'])\n\n# Check the updated length of training_smiles\nlen(training_smiles)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:09.453176Z","iopub.execute_input":"2024-02-19T23:57:09.453601Z","iopub.status.idle":"2024-02-19T23:57:09.460076Z","shell.execute_reply.started":"2024-02-19T23:57:09.453559Z","shell.execute_reply":"2024-02-19T23:57:09.459235Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"40"},"metadata":{}}]},{"cell_type":"code","source":"# Function to calculate weight-adjusted score for each row in new_table\ndef calc_weight_score(row):\n    # Calculate adjustment factor based on molecular weight\n    adj_factor = (900 / row['weight']) ** 0.333\n    # Adjust score accordingly; if adj_factor < 1, set score to 0\n    adj_score = row['score'] * adj_factor if adj_factor >= 1 else 0\n    return adj_score\n\n# Create a deep copy of new_table and calculate weight-adjusted scores for each row\nweight_adjusted = new_table.copy(deep=True)\nweight_adjusted['weight_adj_score'] = weight_adjusted.apply(calc_weight_score, axis=1)\n\n# Sort the weight-adjusted DataFrame by 'weight_adj_score' in ascending order\nweight_adjusted = weight_adjusted.sort_values('weight_adj_score', ascending=True)\n\n# Display the first few rows of the weight-adjusted DataFrame\nweight_adjusted.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:10.937068Z","iopub.execute_input":"2024-02-19T23:57:10.937458Z","iopub.status.idle":"2024-02-19T23:57:10.981021Z","shell.execute_reply.started":"2024-02-19T23:57:10.937424Z","shell.execute_reply":"2024-02-19T23:57:10.980269Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                  smile  gen    id     source  \\\n1009  CCCCCCCCCCCCCCCCCCC(C)CNC(=O)CCCCCCCCCCNC(=O)C...    0  ABMU  generated   \n417   CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(NC(...    0  AAQA  generated   \n743   CC1(C)C(O)CCC2(C)C1CCC1(C)C2CCC2C3C4CC=C5C(C(=...    0  ABCO  generated   \n456   CCCCCCCCCCCCCCCCCCOC1CCC(OCCCCCCCCCCCCCCCCCC)C...    0  AARN  generated   \n1105  CC(C)CN(CC(O)C(Cc1ccccc1)NC(=O)OC1COC2OCCC12)S...    0  ABQM        hiv   \n\n        weight  score_best  score_avg  similarity_to_hiv_inhibitors  \\\n1009  1017.620         NaN        NaN                           NaN   \n417   1162.075         NaN        NaN                           NaN   \n743    891.243         NaN        NaN                           NaN   \n456    859.324         NaN        NaN                           NaN   \n1105   756.004         NaN        NaN                           NaN   \n\n      similarity_to_remdesivir  score  weight_adj_score  \n1009                       NaN   99.9          0.000000  \n417                        NaN   99.9          0.000000  \n743                        NaN   99.9        100.225800  \n456                        NaN   99.9        101.450451  \n1105                       NaN   99.9        105.871660  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smile</th>\n      <th>gen</th>\n      <th>id</th>\n      <th>source</th>\n      <th>weight</th>\n      <th>score_best</th>\n      <th>score_avg</th>\n      <th>similarity_to_hiv_inhibitors</th>\n      <th>similarity_to_remdesivir</th>\n      <th>score</th>\n      <th>weight_adj_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1009</th>\n      <td>CCCCCCCCCCCCCCCCCCC(C)CNC(=O)CCCCCCCCCCNC(=O)C...</td>\n      <td>0</td>\n      <td>ABMU</td>\n      <td>generated</td>\n      <td>1017.620</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(NC(...</td>\n      <td>0</td>\n      <td>AAQA</td>\n      <td>generated</td>\n      <td>1162.075</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>743</th>\n      <td>CC1(C)C(O)CCC2(C)C1CCC1(C)C2CCC2C3C4CC=C5C(C(=...</td>\n      <td>0</td>\n      <td>ABCO</td>\n      <td>generated</td>\n      <td>891.243</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>100.225800</td>\n    </tr>\n    <tr>\n      <th>456</th>\n      <td>CCCCCCCCCCCCCCCCCCOC1CCC(OCCCCCCCCCCCCCCCCCC)C...</td>\n      <td>0</td>\n      <td>AARN</td>\n      <td>generated</td>\n      <td>859.324</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>101.450451</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>CC(C)CN(CC(O)C(Cc1ccccc1)NC(=O)OC1COC2OCCC12)S...</td>\n      <td>0</td>\n      <td>ABQM</td>\n      <td>hiv</td>\n      <td>756.004</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n      <td>105.871660</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Add top 5 SMILES strings from weight_adjusted to training_smiles\ntraining_smiles += list(weight_adjusted.head(5)['smile'])\n\n# Check the updated length of training_smiles\nlen(training_smiles)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:11.107466Z","iopub.execute_input":"2024-02-19T23:57:11.107763Z","iopub.status.idle":"2024-02-19T23:57:11.113593Z","shell.execute_reply.started":"2024-02-19T23:57:11.107735Z","shell.execute_reply":"2024-02-19T23:57:11.112599Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"45"},"metadata":{}}]},{"cell_type":"code","source":"# Import TensorFlow library for deep learning tasks\nimport tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:11.268168Z","iopub.execute_input":"2024-02-19T23:57:11.268481Z","iopub.status.idle":"2024-02-19T23:57:15.951815Z","shell.execute_reply.started":"2024-02-19T23:57:11.268450Z","shell.execute_reply":"2024-02-19T23:57:15.951094Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Import NumPy library for numerical operations\nimport numpy as np\n\n# Import copy function from copy module\nfrom copy import copy\n\n# Import model_from_json function from tensorflow.keras.models module\nfrom tensorflow.keras.models import model_from_json\n\n# Import Sequence class from tensorflow.keras.utils module\nfrom tensorflow.keras.utils import Sequence\n\n# Import Keras module\nimport keras","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:15.953919Z","iopub.execute_input":"2024-02-19T23:57:15.954248Z","iopub.status.idle":"2024-02-19T23:57:15.994292Z","shell.execute_reply.started":"2024-02-19T23:57:15.954217Z","shell.execute_reply":"2024-02-19T23:57:15.993595Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class SmilesTokenizer(object):\n    def __init__(self):\n        \"\"\"\n        Initializes a tokenizer for SMILES strings.\n        \"\"\"\n        # Define lists of atoms, special characters, and padding symbols for SMILES tokenization\n        atoms = [\n        'Li', 'Na', 'Al', 'Si', 'Cl', 'Sc', 'Zn', 'As', 'Se', 'Br', 'Sn', 'Te',\n        'Cn', 'H', 'B', 'C', 'N', 'O', 'F', 'P', 'S', 'K', 'V', 'I'\n        ]\n        special = [\n        '(', ')', '[', ']', '=', '#', '%', '0', '1', '2', '3', '4', '5', '6',\n        '7', '8', '9', '+', '-', 'se', 'te', 'c', 'n', 'o', 's'\n        ]\n        padding = ['G', 'A', 'E']\n\n\n        # Combine atoms, special characters, and padding symbols to create token table\n        self.table = sorted(atoms, key=len, reverse=True) + special + padding\n        self.table_len = len(self.table)\n\n        # Create one-hot encoding dictionary for tokens\n        self.one_hot_dict = {}\n        for i, symbol in enumerate(self.table):\n            vec = np.zeros(self.table_len, dtype=np.float32)\n            vec[i] = 1\n            self.one_hot_dict[symbol] = vec\n\n    def tokenize(self, smiles):\n        \"\"\"\n        Tokenizes a SMILES string into individual tokens.\n        \"\"\"\n        N = len(smiles)\n        i = 0\n        token = []\n\n        # Tokenize the SMILES string\n        timeout = time.time() + 5   # Set timeout for processing\n        while (i < N):\n            for j in range(self.table_len):\n                symbol = self.table[j]\n                if symbol == smiles[i:i + len(symbol)]:\n                    token.append(symbol)\n                    i += len(symbol)\n                    break\n            if time.time() > timeout:\n                break\n        return token\n\n    def one_hot_encode(self, tokenized_smiles):\n        \"\"\"\n        One-hot encodes a list of tokenized SMILES.\n        \"\"\"\n        # Encode tokenized SMILES into one-hot vectors\n        result = np.array(\n            [self.one_hot_dict[symbol] for symbol in tokenized_smiles],\n            dtype=np.float32)\n        result = result.reshape(1, result.shape[0], result.shape[1])\n        return result","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:15.995531Z","iopub.execute_input":"2024-02-19T23:57:15.995884Z","iopub.status.idle":"2024-02-19T23:57:16.010869Z","shell.execute_reply.started":"2024-02-19T23:57:15.995848Z","shell.execute_reply":"2024-02-19T23:57:16.010089Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class LSTMChem(object):\n    def __init__(self, config, session='train'):\n        \"\"\"\n        Initializes the LSTMChem model.\n\n        Args:\n            config: Configuration object containing model settings.\n            session: String indicating the session type ('train', 'generate', or 'finetune').\n        \"\"\"\n        assert session in ['train', 'generate', 'finetune'], \\\n            'one of {train, generate, finetune}'\n\n        self.config = config\n        self.session = session\n        self.model = None\n\n        if self.session == 'train':\n            self.model = self.load(self.config.model_arch_filename,\n                                   self.config.model_weight_filename)\n            self.model.compile(optimizer=self.config.optimizer,\n                               loss='categorical_crossentropy')\n        else:\n            self.model = self.load(self.config.model_arch_filename,\n                                   self.config.model_weight_filename)\n\n    def build_model(self):\n        \"\"\"\n        Builds the LSTMChem model.\n        \"\"\"\n        st = SmilesTokenizer()\n        n_table = len(st.table)\n        weight_init = RandomNormal(mean=0.0,\n                                   stddev=0.05,\n                                   seed=self.config.seed)\n\n        self.model = Sequential()\n        self.model.add(\n            LSTM(units=self.config.units,\n                 input_shape=(None, n_table),\n                 return_sequences=True,\n                 kernel_initializer=weight_init,\n                 dropout=0.3))\n        self.model.add(\n            LSTM(units=self.config.units,\n                 input_shape=(None, n_table),\n                 return_sequences=True,\n                 kernel_initializer=weight_init,\n                 dropout=0.3))\n        self.model.add(\n            Dense(units=n_table,\n                  activation='softmax',\n                  kernel_initializer=weight_init))\n\n        arch = self.model.to_json(indent=2)\n        self.config.model_arch_filename = os.path.join(self.config.exp_dir,\n                                                       'model_arch.json')\n        with open(self.config.model_arch_filename, 'w') as f:\n            f.write(arch)\n\n        self.model.compile(optimizer=self.config.optimizer,\n                           loss='categorical_crossentropy')\n\n    def save(self, checkpoint_path):\n        \"\"\"\n        Saves the model weights.\n\n        Args:\n            checkpoint_path: Path to save the model weights.\n        \"\"\"\n        assert self.model, 'You have to build the model first.'\n\n        print('Saving model ...')\n        self.model.save_weights(checkpoint_path)\n        print('Model saved.')\n\n    def load(self, model_arch_file, checkpoint_file):\n        \"\"\"\n        Loads the model architecture and weights.\n\n        Args:\n            model_arch_file: Path to the model architecture file.\n            checkpoint_file: Path to the model weights file.\n\n        Returns:\n            Loaded Keras model.\n        \"\"\"\n        print(f'Loading model architecture from {model_arch_file} ...')\n        with open(model_arch_file) as f:\n            model = model_from_json(f.read())\n        print(f'Loading model checkpoint from {checkpoint_file} ...')\n        model.load_weights(checkpoint_file)\n        print('Loaded the Model.')\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:16.012027Z","iopub.execute_input":"2024-02-19T23:57:16.012305Z","iopub.status.idle":"2024-02-19T23:57:16.027222Z","shell.execute_reply.started":"2024-02-19T23:57:16.012278Z","shell.execute_reply":"2024-02-19T23:57:16.026425Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class LSTMChemGenerator(object):\n    def __init__(self, modeler):\n        \"\"\"\n        Initializes the LSTMChemGenerator.\n\n        Args:\n            modeler: LSTMChem modeler object containing the session, model, configuration, and tokenizer.\n        \"\"\"\n        self.session = modeler.session\n        self.model = modeler.model\n        self.config = modeler.config\n        self.st = SmilesTokenizer()\n\n    def _generate(self, sequence):\n        \"\"\"\n        Generates a SMILES sequence.\n\n        Args:\n            sequence: Initial SMILES sequence.\n\n        Returns:\n            Generated SMILES sequence.\n        \"\"\"\n        while (sequence[-1] != 'E') and (len(self.st.tokenize(sequence)) <= self.config.smiles_max_length):\n            x = self.st.one_hot_encode(self.st.tokenize(sequence))\n            preds = self.model.predict_on_batch(x)[0][-1]\n            next_idx = self.sample_with_temp(preds)\n            sequence += self.st.table[next_idx]\n\n        sequence = sequence[1:].rstrip('E')\n        return sequence\n\n    def sample_with_temp(self, preds):\n        \"\"\"\n        Samples the next token index with temperature.\n\n        Args:\n            preds: Predicted probabilities for the next token.\n\n        Returns:\n            Index of the sampled token.\n        \"\"\"\n        streched = np.log(preds) / self.config.sampling_temp\n        streched_probs = np.exp(streched) / np.sum(np.exp(streched))\n        return np.random.choice(range(len(streched)), p=streched_probs)\n\n    def sample(self, num=1, start='G'):\n        \"\"\"\n        Samples SMILES sequences.\n\n        Args:\n            num: Number of SMILES sequences to generate.\n            start: Starting token for sequence generation.\n\n        Returns:\n            List of sampled SMILES sequences.\n        \"\"\"\n        sampled = []\n        if self.session == 'generate':\n            for _ in tqdm(range(num)):\n                sampled.append(self._generate(start))\n            return sampled\n        else:\n            from rdkit import Chem, RDLogger\n            RDLogger.DisableLog('rdApp.*')\n            while len(sampled) < num:\n                sequence = self._generate(start)\n                mol = Chem.MolFromSmiles(sequence)\n                if mol is not None:\n                    canon_smiles = Chem.MolToSmiles(mol)\n                    sampled.append(canon_smiles)\n            return sampled","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:16.029767Z","iopub.execute_input":"2024-02-19T23:57:16.030146Z","iopub.status.idle":"2024-02-19T23:57:16.042314Z","shell.execute_reply.started":"2024-02-19T23:57:16.030110Z","shell.execute_reply":"2024-02-19T23:57:16.041452Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_config_from_json(json_file):\n    \"\"\"\n    Reads configuration from a JSON file and returns it as a Bunch object.\n\n    Args:\n        json_file: Path to the JSON configuration file.\n\n    Returns:\n        Configuration Bunch object.\n    \"\"\"\n    with open(json_file, 'r') as config_file:\n        config_dict = json.load(config_file)\n    config = Bunch(config_dict)\n    return config\n\n\ndef process_config(json_file):\n    \"\"\"\n    Processes configuration from a JSON file.\n\n    Args:\n        json_file: Path to the JSON configuration file.\n\n    Returns:\n        Processed configuration Bunch object.\n    \"\"\"\n    config = get_config_from_json(json_file)\n    config.config_file = json_file\n    config.exp_dir = os.path.join(\n        'experiments', time.strftime('%Y-%m-%d/', time.localtime()),\n        config.exp_name)\n    config.tensorboard_log_dir = os.path.join(\n        'experiments', time.strftime('%Y-%m-%d/', time.localtime()),\n        config.exp_name, 'logs/')\n    config.checkpoint_dir = os.path.join(\n        'experiments', time.strftime('%Y-%m-%d/', time.localtime()),\n        config.exp_name, 'checkpoints/')\n    return config","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:57:16.043658Z","iopub.execute_input":"2024-02-19T23:57:16.044021Z","iopub.status.idle":"2024-02-19T23:57:16.054173Z","shell.execute_reply.started":"2024-02-19T23:57:16.043971Z","shell.execute_reply":"2024-02-19T23:57:16.053366Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Set the configuration file path\nCONFIG_FILE = '../input/setscmpz/config.json'\n\n# Process the configuration from the JSON file\nconfig = process_config(CONFIG_FILE)\n\n# Initialize LSTMChem modeler for session 'generate'\nmodeler = LSTMChem(config, session='generate')\n\n# Initialize LSTMChemGenerator using the modeler\ngenerator = LSTMChemGenerator(modeler)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:02:19.716963Z","iopub.execute_input":"2024-02-20T00:02:19.717327Z","iopub.status.idle":"2024-02-20T00:02:22.415080Z","shell.execute_reply.started":"2024-02-20T00:02:19.717296Z","shell.execute_reply":"2024-02-20T00:02:22.414214Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Loading model architecture from ../input/setscmpz/model_arch.json ...\nLoading model checkpoint from ../input/setscmpz/LSTM_Chem-baseline-model-full.hdf5 ...\nLoaded the Model.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the number of samples to generate\nsample_number = 20","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:02:47.173309Z","iopub.execute_input":"2024-02-20T00:02:47.173646Z","iopub.status.idle":"2024-02-20T00:02:47.177202Z","shell.execute_reply.started":"2024-02-20T00:02:47.173617Z","shell.execute_reply":"2024-02-20T00:02:47.176360Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Generate SMILES strings using the LSTMChemGenerator\nbase_generated = generator.sample(num=sample_number)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:03:02.145055Z","iopub.execute_input":"2024-02-20T00:03:02.145415Z","iopub.status.idle":"2024-02-20T00:03:18.786764Z","shell.execute_reply.started":"2024-02-20T00:03:02.145380Z","shell.execute_reply":"2024-02-20T00:03:18.785696Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"100%|██████████| 20/20 [00:16<00:00,  1.20it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def validate_mols(list_of_smiles):\n    \"\"\"\n    Validates a list of SMILES strings and returns valid RDKit Mol objects.\n\n    Args:\n        list_of_smiles: List of SMILES strings to validate.\n\n    Returns:\n        List of valid RDKit Mol objects.\n    \"\"\"\n    valid_mols = []\n    for smi in list_of_smiles:\n        mol = Chem.MolFromSmiles(smi)\n        if mol is not None:\n            valid_mols.append(mol)\n    return valid_mols\n\ndef convert_mols_to_smiles(list_of_mols):\n    \"\"\"\n    Converts a list of RDKit Mol objects to valid SMILES strings.\n\n    Args:\n        list_of_mols: List of RDKit Mol objects to convert.\n\n    Returns:\n        List of valid SMILES strings.\n    \"\"\"\n    valid_smiles = [Chem.MolToSmiles(mol) for mol in list_of_mols]\n    return valid_smiles","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:03:52.498755Z","iopub.execute_input":"2024-02-20T00:03:52.499106Z","iopub.status.idle":"2024-02-20T00:03:52.505075Z","shell.execute_reply.started":"2024-02-20T00:03:52.499075Z","shell.execute_reply":"2024-02-20T00:03:52.503940Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Validate generated molecules and convert them to SMILES strings\nbase_generated_mols = validate_mols(base_generated)\nbase_generated_smiles = convert_mols_to_smiles(base_generated_mols)\n\n# Shuffle the list of generated SMILES strings twice for randomness\nrandom.shuffle(base_generated_smiles)\nrandom.shuffle(base_generated_smiles)\n\n# Select a subset of generated SMILES strings for training data to refine the molecule generator\ntraining_smiles += base_generated_smiles[0:5]\n\n# Check the updated length of training_smiles\nlen(training_smiles)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:04:17.124382Z","iopub.execute_input":"2024-02-20T00:04:17.124756Z","iopub.status.idle":"2024-02-20T00:04:17.137643Z","shell.execute_reply.started":"2024-02-20T00:04:17.124720Z","shell.execute_reply":"2024-02-20T00:04:17.136642Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"50"},"metadata":{}}]},{"cell_type":"code","source":"# Read the master results table from the previous generation\nmaster_table = pd.read_csv('./master_results_table_gen' + str(GLOBAL_GENERATION-1) + '.csv', sep=',')\n\n# Display the first few rows of the master table\nmaster_table.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:04:57.123818Z","iopub.execute_input":"2024-02-20T00:04:57.124182Z","iopub.status.idle":"2024-02-20T00:04:57.147552Z","shell.execute_reply.started":"2024-02-20T00:04:57.124149Z","shell.execute_reply":"2024-02-20T00:04:57.146759Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                               smile  gen    id     source  \\\n0      C#Cc1cccc(Nc2ncnc3c2c(C(C)(C)C)c(C)n3CCC#N)c1    0  AAAA  generated   \n1    CN(C)CCC(CCNC(=O)Oc1ccccc1)(Cc1ccccc1)NC1CCCCC1    0  ABCP  generated   \n2               Cc1csc(SCC(=O)Nc2ccc(OC3CCCC3)nc2)n1    0  ABCQ  generated   \n3               CC1(C)Cc2cccc(C(C#N)NC(=O)C3CC3)c2C1    0  ABCR  generated   \n4  CC(C(=O)Nc1ccccc1N1CCCC1)n1nc(C(F)(F)F)cc1C(F)...    0  ABCS  generated   \n\n    weight  score_best  score_avg  similarity_to_hiv_inhibitors  \\\n0  357.461         NaN        NaN                           NaN   \n1  437.628         NaN        NaN                           NaN   \n2  349.481         NaN        NaN                           NaN   \n3  268.360         NaN        NaN                           NaN   \n4  420.357         NaN        NaN                           NaN   \n\n   similarity_to_remdesivir  score  \n0                       NaN   99.9  \n1                       NaN   99.9  \n2                       NaN   99.9  \n3                       NaN   99.9  \n4                       NaN   99.9  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smile</th>\n      <th>gen</th>\n      <th>id</th>\n      <th>source</th>\n      <th>weight</th>\n      <th>score_best</th>\n      <th>score_avg</th>\n      <th>similarity_to_hiv_inhibitors</th>\n      <th>similarity_to_remdesivir</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C#Cc1cccc(Nc2ncnc3c2c(C(C)(C)C)c(C)n3CCC#N)c1</td>\n      <td>0</td>\n      <td>AAAA</td>\n      <td>generated</td>\n      <td>357.461</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CN(C)CCC(CCNC(=O)Oc1ccccc1)(Cc1ccccc1)NC1CCCCC1</td>\n      <td>0</td>\n      <td>ABCP</td>\n      <td>generated</td>\n      <td>437.628</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cc1csc(SCC(=O)Nc2ccc(OC3CCCC3)nc2)n1</td>\n      <td>0</td>\n      <td>ABCQ</td>\n      <td>generated</td>\n      <td>349.481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CC1(C)Cc2cccc(C(C#N)NC(=O)C3CC3)c2C1</td>\n      <td>0</td>\n      <td>ABCR</td>\n      <td>generated</td>\n      <td>268.360</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CC(C(=O)Nc1ccccc1N1CCCC1)n1nc(C(F)(F)F)cc1C(F)...</td>\n      <td>0</td>\n      <td>ABCS</td>\n      <td>generated</td>\n      <td>420.357</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Write training SMILES to a file for the current generation\nwith open('gen' + str(GLOBAL_GENERATION) + '_training.smi', 'w') as f:\n    for item in training_smiles:\n        f.write(\"%s\\n\" % item)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:05:50.663353Z","iopub.execute_input":"2024-02-20T00:05:50.663735Z","iopub.status.idle":"2024-02-20T00:05:50.668793Z","shell.execute_reply.started":"2024-02-20T00:05:50.663702Z","shell.execute_reply":"2024-02-20T00:05:50.667989Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class LSTMChemFinetuner(LSTMChemGenerator):\n    def __init__(self, modeler, finetune_data_loader):\n        \"\"\"\n        Initializes the LSTMChemFinetuner.\n\n        Args:\n            modeler: LSTMChem modeler object containing the session, model, configuration, and tokenizer.\n            finetune_data_loader: Data loader for fine-tuning the model.\n        \"\"\"\n        self.session = modeler.session\n        self.model = modeler.model\n        self.config = modeler.config\n        self.finetune_data_loader = finetune_data_loader\n        self.st = SmilesTokenizer()\n\n    def finetune(self):\n        \"\"\"\n        Fine-tunes the LSTMChem model.\n\n        Returns:\n            Training history of the fine-tuning process.\n        \"\"\"\n        # Compile the model with specified optimizer and loss function\n        self.model.compile(optimizer=self.config.optimizer,\n                           loss='categorical_crossentropy')\n\n        # Fit the model using the fine-tuning data loader\n        history = self.model.fit_generator(\n            self.finetune_data_loader,\n            steps_per_epoch=self.finetune_data_loader.__len__(),\n            epochs=self.config.finetune_epochs,\n            verbose=self.config.verbose_training,\n            use_multiprocessing=True,\n            shuffle=True)\n        \n        return history","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:06:16.883117Z","iopub.execute_input":"2024-02-20T00:06:16.883491Z","iopub.status.idle":"2024-02-20T00:06:16.890878Z","shell.execute_reply.started":"2024-02-20T00:06:16.883457Z","shell.execute_reply":"2024-02-20T00:06:16.889861Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Load and process the configuration from the specified JSON file\nconfig = process_config('../input/setscmpz/config.json')\n\n# Update the model weight filename and finetune data filename in the configuration\n# config['model_weight_filename'] = 'finetuned_gen' + str(GLOBAL_GENERATION-1) + '.hdf5'\nconfig['model_weight_filename'] = '../input/setscmpz/LSTM_Chem-baseline-model-full.hdf5'\nconfig['finetune_data_filename'] = 'gen' + str(GLOBAL_GENERATION) + '_training.smi'\n\n# Print the updated configuration\nprint(config)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:07:03.234728Z","iopub.execute_input":"2024-02-20T00:07:03.235117Z","iopub.status.idle":"2024-02-20T00:07:03.244481Z","shell.execute_reply.started":"2024-02-20T00:07:03.235082Z","shell.execute_reply":"2024-02-20T00:07:03.243482Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"batch_size: 512\ncheckpoint_dir: experiments/2024-02-20/LSTM_Chem/checkpoints/\ncheckpoint_mode: min\ncheckpoint_monitor: val_loss\ncheckpoint_save_best_only: false\ncheckpoint_save_weights_only: true\ncheckpoint_verbose: 1\nconfig_file: ../input/setscmpz/config.json\ndata_filename: ../input/setscmpz/dataset_cleansed.smi\ndata_length: 0\nexp_dir: experiments/2024-02-20/LSTM_Chem\nexp_name: LSTM_Chem\nfinetune_batch_size: 1\nfinetune_data_filename: gen3_training.smi\nfinetune_epochs: 20\nmodel_arch_filename: ../input/setscmpz/model_arch.json\nmodel_weight_filename: ../input/setscmpz/LSTM_Chem-baseline-model-full.hdf5\nnum_epochs: 42\noptimizer: adam\nsampling_temp: 0.75\nseed: 71\nsmiles_max_length: 128\ntensorboard_log_dir: experiments/2024-02-20/LSTM_Chem/logs/\ntensorboard_write_graph: true\ntrain_smi_max_len: 128\nunits: 256\nvalidation_split: 0.1\nverbose_training: true\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataLoader(Sequence):\n    def __init__(self, config, data_type='train'):\n        \"\"\"\n        Initializes the DataLoader.\n\n        Args:\n            config: Configuration object.\n            data_type: Type of data ('train', 'valid', or 'finetune').\n        \"\"\"\n        self.config = config\n        self.data_type = data_type\n        assert self.data_type in ['train', 'valid', 'finetune']\n\n        self.max_len = 0\n\n        if self.data_type == 'train':\n            self.smiles = self._load(self.config.data_filename)\n        elif self.data_type == 'finetune':\n            self.smiles = self._load(self.config.finetune_data_filename)\n        else:\n            pass\n\n        self.st = SmilesTokenizer()\n        self.one_hot_dict = self.st.one_hot_dict\n\n        self.tokenized_smiles = self._tokenize(self.smiles)\n\n        if self.data_type in ['train', 'valid']:\n            self.idx = np.arange(len(self.tokenized_smiles))\n            self.valid_size = int(\n                np.ceil(\n                    len(self.tokenized_smiles) * self.config.validation_split))\n            np.random.seed(self.config.seed)\n            np.random.shuffle(self.idx)\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of batches.\n\n        Returns:\n            Number of batches.\n        \"\"\"\n        target_tokenized_smiles = self._set_data()\n        if self.data_type in ['train', 'valid']:\n            ret = int(\n                np.ceil(\n                    len(target_tokenized_smiles) /\n                    float(self.config.batch_size)))\n        else:\n            ret = int(\n                np.ceil(\n                    len(target_tokenized_smiles) /\n                    float(self.config.finetune_batch_size)))\n        return ret\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Generates one batch of data.\n\n        Args:\n            idx: Index of the batch.\n\n        Returns:\n            Tuple of input and target data arrays.\n        \"\"\"\n        target_tokenized_smiles = self._set_data()\n        if self.data_type in ['train', 'valid']:\n            data = target_tokenized_smiles[idx *\n                                           self.config.batch_size:(idx + 1) *\n                                           self.config.batch_size]\n        else:\n            data = target_tokenized_smiles[idx *\n                                           self.config.finetune_batch_size:\n                                           (idx + 1) *\n                                           self.config.finetune_batch_size]\n        data = self._padding(data)\n\n        self.X, self.y = [], []\n        for tp_smi in data:\n            X = [self.one_hot_dict[symbol] for symbol in tp_smi[:-1]]\n            self.X.append(X)\n            y = [self.one_hot_dict[symbol] for symbol in tp_smi[1:]]\n            self.y.append(y)\n\n        self.X = np.array(self.X, dtype=np.float32)\n        self.y = np.array(self.y, dtype=np.float32)\n\n        return self.X, self.y\n\n    def _set_data(self):\n        \"\"\"\n        Sets the data for training, validation, or fine-tuning.\n\n        Returns:\n            List of tokenized SMILES strings.\n        \"\"\"\n        if self.data_type == 'train':\n            ret = [\n                self.tokenized_smiles[self.idx[i]]\n                for i in self.idx[self.valid_size:]\n            ]\n        elif self.data_type == 'valid':\n            ret = [\n                self.tokenized_smiles[self.idx[i]]\n                for i in self.idx[:self.valid_size]\n            ]\n        else:\n            ret = self.tokenized_smiles\n        return ret\n\n    def _load(self, data_filename):\n        \"\"\"\n        Loads SMILES data from file.\n\n        Args:\n            data_filename: Path to the data file.\n\n        Returns:\n            List of SMILES strings.\n        \"\"\"\n        length = self.config.data_length\n        print('loading SMILES...')\n        with open(data_filename) as f:\n            smiles = [s.rstrip() for s in f]\n        if length != 0:\n            smiles = smiles[:length]\n        print('done.')\n        return smiles\n\n    def _tokenize(self, smiles):\n        \"\"\"\n        Tokenizes SMILES strings.\n\n        Args:\n            smiles: List of SMILES strings.\n\n        Returns:\n            List of tokenized SMILES strings.\n        \"\"\"\n        assert isinstance(smiles, list)\n        print('tokenizing SMILES...')\n        tokenized_smiles = [self.st.tokenize(smi) for smi in tqdm(smiles)]\n\n        if self.data_type == 'train':\n            for tokenized_smi in tokenized_smiles:\n                length = len(tokenized_smi)\n                if self.max_len < length:\n                    self.max_len = length\n            self.config.train_smi_max_len = self.max_len\n        print('done.')\n        return tokenized_smiles\n\n    def _pad(self, tokenized_smi):\n        \"\"\"\n        Pads tokenized SMILES strings.\n\n        Args:\n            tokenized_smi: Tokenized SMILES string.\n\n        Returns:\n            Padded tokenized SMILES string.\n        \"\"\"\n        return ['G'] + tokenized_smi + ['E'] + [\n            'A' for _ in range(self.max_len - len(tokenized_smi))\n        ]\n\n    def _padding(self, data):\n        \"\"\"\n        Pads data.\n\n        Args:\n            data: List of tokenized SMILES strings.\n\n        Returns:\n            List of padded SMILES strings.\n        \"\"\"\n        padded_smiles = [self._pad(t_smi) for t_smi in data]\n        return padded_smiles","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:08:41.314041Z","iopub.execute_input":"2024-02-20T00:08:41.314414Z","iopub.status.idle":"2024-02-20T00:08:41.339230Z","shell.execute_reply.started":"2024-02-20T00:08:41.314382Z","shell.execute_reply":"2024-02-20T00:08:41.338263Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Initialize the modeler for fine-tuning and create a data loader for fine-tuning\nmodeler = LSTMChem(config, session='finetune')\nfinetune_dl = DataLoader(config, data_type='finetune')\n\n# Initialize the LSTMChemFinetuner with the modeler and fine-tuning data loader\nfinetuner = LSTMChemFinetuner(modeler, finetune_dl)\n\n# Fine-tune the model using the finetuner\nfinetuner.finetune()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:09:34.478561Z","iopub.execute_input":"2024-02-20T00:09:34.478927Z","iopub.status.idle":"2024-02-20T00:15:25.942653Z","shell.execute_reply.started":"2024-02-20T00:09:34.478895Z","shell.execute_reply":"2024-02-20T00:15:25.941510Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Loading model architecture from ../input/setscmpz/model_arch.json ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [00:00<00:00, 1945.81it/s]","output_type":"stream"},{"name":"stdout","text":"Loading model checkpoint from ../input/setscmpz/LSTM_Chem-baseline-model-full.hdf5 ...\nLoaded the Model.\nloading SMILES...\ndone.\ntokenizing SMILES...\ndone.\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n","output_type":"stream"},{"name":"stdout","text":"50/50 [==============================] - 22s 343ms/step - loss: 0.7133\nEpoch 2/20\n50/50 [==============================] - 17s 339ms/step - loss: 0.5360\nEpoch 3/20\n50/50 [==============================] - 18s 355ms/step - loss: 0.5283\nEpoch 4/20\n50/50 [==============================] - 17s 341ms/step - loss: 0.4501\nEpoch 5/20\n50/50 [==============================] - 17s 341ms/step - loss: 0.3896\nEpoch 6/20\n50/50 [==============================] - 17s 345ms/step - loss: 0.3377\nEpoch 7/20\n50/50 [==============================] - 18s 350ms/step - loss: 0.3723\nEpoch 8/20\n50/50 [==============================] - 17s 344ms/step - loss: 0.3289\nEpoch 9/20\n50/50 [==============================] - 18s 351ms/step - loss: 0.3022\nEpoch 10/20\n50/50 [==============================] - 17s 340ms/step - loss: 0.2804\nEpoch 11/20\n50/50 [==============================] - 17s 346ms/step - loss: 0.2687\nEpoch 12/20\n50/50 [==============================] - 17s 348ms/step - loss: 0.2617\nEpoch 13/20\n50/50 [==============================] - 17s 344ms/step - loss: 0.2803\nEpoch 14/20\n50/50 [==============================] - 17s 346ms/step - loss: 0.2575\nEpoch 15/20\n50/50 [==============================] - 17s 341ms/step - loss: 0.2700\nEpoch 16/20\n50/50 [==============================] - 17s 348ms/step - loss: 0.2442\nEpoch 17/20\n50/50 [==============================] - 17s 343ms/step - loss: 0.2175\nEpoch 18/20\n50/50 [==============================] - 17s 346ms/step - loss: 0.2090\nEpoch 19/20\n50/50 [==============================] - 17s 345ms/step - loss: 0.2239\nEpoch 20/20\n50/50 [==============================] - 17s 348ms/step - loss: 0.2025\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x79039f5892d0>"},"metadata":{}}]},{"cell_type":"code","source":"finetuner.model.save_weights('finetuned_gen' + str(GLOBAL_GENERATION) + '.hdf5')","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:16:18.798243Z","iopub.execute_input":"2024-02-20T00:16:18.798618Z","iopub.status.idle":"2024-02-20T00:16:18.820337Z","shell.execute_reply.started":"2024-02-20T00:16:18.798588Z","shell.execute_reply":"2024-02-20T00:16:18.819640Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Update the model weight filename in the configuration\nconfig['model_weight_filename'] = './finetuned_gen' + str(GLOBAL_GENERATION) + '.hdf5'\n\n# Initialize the modeler and generator for generation using the updated configuration\nmodeler = LSTMChem(config, session='generate')\ngenerator = LSTMChemGenerator(modeler)\n\n# Print the updated configuration\nprint(config)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:16:40.038036Z","iopub.execute_input":"2024-02-20T00:16:40.038411Z","iopub.status.idle":"2024-02-20T00:16:40.357670Z","shell.execute_reply.started":"2024-02-20T00:16:40.038379Z","shell.execute_reply":"2024-02-20T00:16:40.356712Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Loading model architecture from ../input/setscmpz/model_arch.json ...\nLoading model checkpoint from ./finetuned_gen3.hdf5 ...\nLoaded the Model.\nbatch_size: 512\ncheckpoint_dir: experiments/2024-02-20/LSTM_Chem/checkpoints/\ncheckpoint_mode: min\ncheckpoint_monitor: val_loss\ncheckpoint_save_best_only: false\ncheckpoint_save_weights_only: true\ncheckpoint_verbose: 1\nconfig_file: ../input/setscmpz/config.json\ndata_filename: ../input/setscmpz/dataset_cleansed.smi\ndata_length: 0\nexp_dir: experiments/2024-02-20/LSTM_Chem\nexp_name: LSTM_Chem\nfinetune_batch_size: 1\nfinetune_data_filename: gen3_training.smi\nfinetune_epochs: 20\nmodel_arch_filename: ../input/setscmpz/model_arch.json\nmodel_weight_filename: ./finetuned_gen3.hdf5\nnum_epochs: 42\noptimizer: adam\nsampling_temp: 0.75\nseed: 71\nsmiles_max_length: 128\ntensorboard_log_dir: experiments/2024-02-20/LSTM_Chem/logs/\ntensorboard_write_graph: true\ntrain_smi_max_len: 128\nunits: 256\nvalidation_split: 0.1\nverbose_training: true\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate a large number of SMILES strings using the generator\nsample_number = 500\nsampled_smiles = generator.sample(num=sample_number)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:21:51.203696Z","iopub.execute_input":"2024-02-20T00:21:51.204039Z","iopub.status.idle":"2024-02-20T00:27:57.756897Z","shell.execute_reply.started":"2024-02-20T00:21:51.203990Z","shell.execute_reply":"2024-02-20T00:27:57.755945Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"100%|██████████| 500/500 [06:06<00:00,  1.36it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Analyze the generated SMILES strings:\n# - Evaluate validity, uniqueness, and originality\nvalid_mols = []\nfor smi in sampled_smiles:\n    mol = Chem.MolFromSmiles(smi)\n    if mol is not None:\n        valid_mols.append(mol)\n\n# Calculate validity\nprint('Validity:', f'{len(valid_mols) / sample_number:.2%}')\n\n# Calculate uniqueness\nvalid_smiles = [Chem.MolToSmiles(mol) for mol in valid_mols]\nprint('Uniqueness:', f'{len(set(valid_smiles)) / len(valid_smiles):.2%}')\n\n# Determine originality by checking how many valid SMILES are not in the training data\nimport pandas as pd\ntraining_data = pd.read_csv('../input/setscmpz/dataset_cleansed.smi', header=None)\ntraining_set = set(list(training_data[0]))\noriginal = [smile for smile in set(valid_smiles) if smile not in training_set]\nprint('Originality:', f'{len(set(original)) / len(set(valid_smiles)):.2%}')","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:30:37.013869Z","iopub.execute_input":"2024-02-20T00:30:37.014269Z","iopub.status.idle":"2024-02-20T00:30:37.933899Z","shell.execute_reply.started":"2024-02-20T00:30:37.014236Z","shell.execute_reply":"2024-02-20T00:30:37.933058Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1ccc(C(NC(=O)C(O)c2cccc(C(C)(C)C)c2)sc1'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CCCCCn1c(SCC(=O)Nc2cccc(OC)c2)nc2ccccc21)c1ccc(C(=O)OC)cc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CCCCCn1c(SCC(=O)Nc2cccc(OC)c2)nc2ccccc21)c1ccc(C(=O)OC)cc1' for input: 'CCCCCn1c(SCC(=O)Nc2cccc(OC)c2)nc2ccccc21)c1ccc(C(=O)OC)cc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 6 7 23\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CCCCCn1c(SCC(=O)NCc2ccco2)nc2ccccc21)c1ccc(C(=O)OCC)cc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CCCCCn1c(SCC(=O)NCc2ccco2)nc2ccccc21)c1ccc(C(=O)OCC)cc1' for input: 'CCCCCn1c(SCC(=O)NCc2ccco2)nc2ccccc21)c1ccc(C(=O)OCC)cc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 11 22\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 18 19\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC(=O)Nc1ccc(OC2=C(C)N(C)Cc3ccccc3)cc2)cc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC(=O)Nc1ccc(OC2=C(C)N(C)Cc3ccccc3)cc2)cc1' for input: 'CC(=O)Nc1ccc(OC2=C(C)N(C)Cc3ccccc3)cc2)cc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 7 8 9 10 11\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CCCCCn1c(SCC(=O)NCc2ccco2)nc2ccccc21)c1ccsc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CCCCCn1c(SCC(=O)NCc2ccco2)nc2ccccc21)c1ccsc1' for input: 'CCCCCn1c(SCC(=O)NCc2ccco2)nc2ccccc21)c1ccsc1'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC(=O)N1C(C)C(=O)N(C)Cc2ccc(F)cc2)c1C\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC(=O)N1C(C)C(=O)N(C)Cc2ccc(F)cc2)c1C' for input: 'CC(=O)N1C(C)C(=O)N(C)Cc2ccc(F)cc2)c1C'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC1(C)Nc2ccc(OCC(=O)N(C)CCc3ccc(F)cc3)cc2)c1C\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC1(C)Nc2ccc(OCC(=O)N(C)CCc3ccc(F)cc3)cc2)c1C' for input: 'CC1(C)Nc2ccc(OCC(=O)N(C)CCc3ccc(F)cc3)cc2)c1C'\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1csc(SCC(=O)N2CCOCC2)c1=CC(=O)N(C)Cc1scc(C(=O)N(C)CCc1ccccc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'CC(C)=CC(C)C(CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: Cc1cnc(C(=O)N2CC3CCCN3CC(=O)N(C)CCc3ccccc3)n2)s1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'Cc1cnc(C(=O)N2CC3CCCN3CC(=O)N(C)CCc3ccccc3)n2)s1' for input: 'Cc1cnc(C(=O)N2CC3CCCN3CC(=O)N(C)CCc3ccccc3)n2)s1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 11 12 16\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: Cc1csc(SC2(C)C)n2CC(=O)N2CCCCC2)c1NC(=O)NC(C#N)C(C)(C)C\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'Cc1csc(SC2(C)C)n2CC(=O)N2CCCCC2)c1NC(=O)NC(C#N)C(C)(C)C' for input: 'Cc1csc(SC2(C)C)n2CC(=O)N2CCCCC2)c1NC(=O)NC(C#N)C(C)(C)C'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 6 7 21\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 10 11 12 13 14 15 16 17 18\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1ccc(C(NC(=O)C(O)c2ccc(OC3CCCC3)c(O)c2)sc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 22 23\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 11 18\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCOC(=O)C=CC(CCCCCCCCCCCCCCCCCCCCCCCCCC'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: Cc1csc(SCC(=O)N2CCCCC2)n1N=C1CCc2ccccc2)n1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'Cc1csc(SCC(=O)N2CCCCC2)n1N=C1CCc2ccccc2)n1' for input: 'Cc1csc(SCC(=O)N2CCCCC2)n1N=C1CCc2ccccc2)n1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 13\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 6 7 21\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 17 18\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'COc1cc(C(=O)OCc2ccc(OC)c(OC)c2)ccc1OCCN1CCN(C(=O)OC(C)(CCCCCCCCCCCCCC(=O)NO)CC1'\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1csc(SC2CCN(S(=O)(=O)Cc2ccc(F)cc2)C1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 11 12 13 14 21\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC(=O)Nc1ccc(OC2=C(C)Nc3occc3C)cc2)cc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC(=O)Nc1ccc(OC2=C(C)Nc3occc3C)cc2)cc1' for input: 'CC(=O)Nc1ccc(OC2=C(C)Nc3occc3C)cc2)cc1'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: Cc1csc(SC2(C)Cc3cccc(C(F)(F)F)c3)C2)n1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'Cc1csc(SC2(C)Cc3cccc(C(F)(F)F)c3)C2)n1' for input: 'Cc1csc(SC2(C)Cc3cccc(C(F)(F)F)c3)C2)n1'\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(O)C(COC(=O)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: C#Cc1cccc(Nc2ncnc3oc(C(C)(C)C)cc33)c2)c1OC\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'C#Cc1cccc(Nc2ncnc3oc(C(C)(C)C)cc33)c2)c1OC' for input: 'C#Cc1cccc(Nc2ncnc3oc(C(C)(C)C)cc33)c2)c1OC'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 11 24\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 14 15 16 25 26\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1csc(SC2CCCCC2)n1C1CC(=O)N(C(C#N)CC(C(=O)NCc2ccc(F)cc2)C1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 13 14 15 18 21\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 4 5 6 21 22\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 13 14 15\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 13 14 15\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: Cc1csc(SC2(=O)NC(Cc3ccccc3)c3ccccc3)nc2)n1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'Cc1csc(SC2(=O)NC(Cc3ccccc3)c3ccccc3)nc2)n1' for input: 'Cc1csc(SC2(=O)NC(Cc3ccccc3)c3ccccc3)nc2)n1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 6 7 8 9 10 11 12 17 18 19 20 21 22\n[00:30:37] Explicit valence for atom # 10 O, 3, is greater than permitted\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 13 14 15\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 14 15 16 21 22\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 17 18\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 13\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 13\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1ccc(C(NC(=O)C(O)c2ccc(C(CC)c2ccccc2)c2ccccc2)cc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 6 17 18 19 20 21 22\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 4 6 7 8 9\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'CCCCC(CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 12 18\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'Cc1ccc(C(NC(=O)C(C#N)c2cccc([N+](=O)[O-])c2)s1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 20 21 22 23 24\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 13 14 15 16 19\n[00:30:37] SMILES Parse Error: ring closure 2 duplicates bond between atom 12 and atom 16 for input: 'CC(C)(C)C(=O)Nc1ccc(OC2(C(F)F)c2ccc(F)cc2)cc1'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CCCCCn1c2ccccc2c2c(C(=O)OCC)cc(=O)[nH]2)n1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CCCCCn1c2ccccc2c2c(C(=O)OCC)cc(=O)[nH]2)n1' for input: 'CCCCCn1c2ccccc2c2c(C(=O)OCC)cc(=O)[nH]2)n1'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC(C)(C)C(=O)NCc1ccc(OC2CCCC2)s1)c1ccccc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC(C)(C)C(=O)NCc1ccc(OC2CCCC2)s1)c1ccccc1' for input: 'CC(C)(C)C(=O)NCc1ccc(OC2CCCC2)s1)c1ccccc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 18 19 20 21 22\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 12 13 14 23 24\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 4\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'CC1CC(C(=O)N(Cc2ccc(C(=O)N(C)Cc3ccccc3)c2)CC1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 16 17 18 19 21\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC1(C)Cc2cccc(C(O)(C#N)NC(=O)C3)c3CCCC1)CC(=O)O\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC1(C)Cc2cccc(C(O)(C#N)NC(=O)C3)c3CCCC1)CC(=O)O' for input: 'CC1(C)Cc2cccc(C(O)(C#N)NC(=O)C3)c3CCCC1)CC(=O)O'\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'COc1ccc(-c2cc(-c2ncc(C)o2)cc1OC'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 17 18\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 18 19\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10 17 18\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC(=O)Nc1ccc(CN2CCC(=O)N(C)CCCC)c2)cc1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC(=O)Nc1ccc(CN2CCC(=O)N(C)CCCC)c2)cc1' for input: 'CC(=O)Nc1ccc(CN2CCC(=O)N(C)CCCC)c2)cc1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 4 5 21\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'COc1cc(C(=O)OCc2ccc([N+](=O)[O-])cc2)ccc1OCCN1CCN(C(=O)OC(C)(CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(=O)NO)CC1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 14 15 16 23 24\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 9 10 11 14 17\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: Cc1csc(SC2(C#N)Cc3ncc(C(C)(C)C)c3)n2)n1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'Cc1csc(SC2(C#N)Cc3ncc(C(C)(C)C)c3)n2)n1' for input: 'Cc1csc(SC2(C#N)Cc3ncc(C(C)(C)C)c3)n2)n1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 6 7 21\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'CC(C)CC(CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCNC(=O)OCc1ccc(O)cc1'\n[00:30:37] SMILES Parse Error: extra close parentheses while parsing: CC(C)n1c(N)ncc(C(=O)N2CCCCC2)c1=O)c1ccco1\n[00:30:37] SMILES Parse Error: Failed parsing SMILES 'CC(C)n1c(N)ncc(C(=O)N2CCCCC2)c1=O)c1ccco1' for input: 'CC(C)n1c(N)ncc(C(=O)N2CCCCC2)c1=O)c1ccco1'\n[00:30:37] Explicit valence for atom # 16 C, 5, is greater than permitted\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 15 16 17 18 20\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 6 7 8 15 17\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 8 9 10\n[00:30:37] SMILES Parse Error: extra open parentheses for input: 'COc1cc(C(=O)OCc2ccc(OC(C)(C)C)cc2)ccc1OCCN1CCN(C(=O)OC(C)(CCCCN)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC1'\n[00:30:37] Can't kekulize mol.  Unkekulized atoms: 1 2 3 4 13\n[00:30:37] Explicit valence for atom # 6 C, 5, is greater than permitted\n","output_type":"stream"},{"name":"stdout","text":"Validity: 81.20%\nUniqueness: 60.10%\nOriginality: 100.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove duplicate valid SMILES strings to ensure uniqueness\nvalid_smiles = list(set(valid_smiles))\n# Calculate the number of unique valid SMILES strings\nlen(valid_smiles)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:31:20.036563Z","iopub.execute_input":"2024-02-20T00:31:20.036917Z","iopub.status.idle":"2024-02-20T00:31:20.042283Z","shell.execute_reply.started":"2024-02-20T00:31:20.036887Z","shell.execute_reply":"2024-02-20T00:31:20.041496Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"244"},"metadata":{}}]},{"cell_type":"code","source":"# Function to append new molecules to the tracking table and prepare them for export\ndef append_to_tracking_table(master_table, mols_to_append, source, generation):\n    # Initialize lists for tracking and table rows\n    mols_to_export = []\n    rows_list = []\n    \n    # Filter master_table for the current generation\n    master_table_gen = master_table[master_table['gen'] == generation]\n    \n    # Generate a unique ID code for the new molecules\n    if master_table_gen.shape[0] == 0:\n        id_code = 'AAAA'\n    else:\n        master_table_gen_ids = master_table_gen.sort_values('id', ascending=True)\n        master_table_gen_max_id = master_table_gen_ids.tail(1)\n        key = master_table_gen_max_id['id'].keys()[0]\n        id_code = iterate_alpha(str(master_table_gen_max_id['id'][key]))\n        \n    # Load training data for comparison\n    training_data = pd.read_csv('../input/setscmpz/dataset_cleansed.smi', header=None)\n    training_set = set(list(training_data[0]))\n    \n    # Iterate through molecules to append\n    for mol in mols_to_append:\n        pm = Chem.PropertyMol.PropertyMol(mol)\n        title = 'id' + str(id_code) + 'gen'+ str(generation)\n        print(title)\n        # Set a title property for tracking\n        pm.SetProp('Title', title)\n        mols_to_export.append(pm)\n\n        # Track molecule details in pandas dataframe\n        mol_dict = {}\n        mol_dict['id'] = id_code\n        mol_dict['gen'] = generation\n        smile = Chem.MolToSmiles(mol)\n        assert type(smile) == type('string')\n        mol_dict['smile'] = smile\n\n        # Determine source of molecule\n        if (source != 'hiv' and source != 'manual' and source != 'baseline') and (smile in training_set):\n            mol_dict['source'] = 'training'\n        else:\n            mol_dict['source'] = source\n        mol_dict['score'] = 99.9\n\n        rows_list.append(mol_dict)\n        id_code = iterate_alpha(id_code)\n        \n    # Create a pandas dataframe from the list of rows\n    df = pd.DataFrame(rows_list)\n    return df, mols_to_export ","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:31:53.008168Z","iopub.execute_input":"2024-02-20T00:31:53.008516Z","iopub.status.idle":"2024-02-20T00:31:53.045240Z","shell.execute_reply.started":"2024-02-20T00:31:53.008487Z","shell.execute_reply":"2024-02-20T00:31:53.044314Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Function to iterate an alpha code by incrementing it\ndef iterate_alpha(alpha_code):\n    # Convert alpha code to a list of ASCII numbers representing each character\n    numbers = [ord(letter) for letter in alpha_code]\n    \n    # Increment the alpha code based on specific conditions\n    if numbers[3] + 1 > 90:  # If the fourth character is 'Z'\n        if numbers[2] + 1 > 90:  # If the third character is 'Z'\n            if numbers[1] + 1 > 90:  # If the second character is 'Z'\n                if numbers[0] + 1 > 90:  # If the first character is 'Z', raise an error (too long for alpha code)\n                    raise ValueError('Too long for alpha code')\n                else:\n                    # Reset the fourth, third, and second characters to 'A' and increment the first character\n                    numbers[3] = 65\n                    numbers[2] = 65\n                    numbers[1] = 65\n                    numbers[0] = numbers[0] + 1\n            else:\n                # Reset the fourth character to 'A' and increment the third and second characters\n                numbers[3] = 65\n                numbers[2] = 65\n                numbers[1] = numbers[1] + 1\n        else:\n            # Reset the fourth character to 'A' and increment the third character\n            numbers[3] = 65\n            numbers[2] = numbers[2] + 1\n    else:\n        # Increment the fourth character\n        numbers[3] = numbers[3] + 1\n    \n    # Convert the list of ASCII numbers back to a string representing the new alpha code\n    new_code = \"\".join(chr(number) for number in numbers)\n    return new_code\n\n# Example usage: Incrementing the alpha code 'AAAA' to the next code\niterate_alpha('AAAA')","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:37:25.203311Z","iopub.execute_input":"2024-02-20T00:37:25.203669Z","iopub.status.idle":"2024-02-20T00:37:25.215948Z","shell.execute_reply.started":"2024-02-20T00:37:25.203639Z","shell.execute_reply":"2024-02-20T00:37:25.215184Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'AAAB'"},"metadata":{}}]},{"cell_type":"code","source":"# Validate the generated SMILES strings to ensure they represent valid molecules\nmols_for_next_generation = validate_mols(valid_smiles)\n\n# Load the master table from the previous generation\nmaster_table = pd.read_csv('./master_results_table_gen' + str(GLOBAL_GENERATION-1) +'.csv',sep=',')\n\n# Append new molecules to the master table for tracking and analysis\nnew_mols_to_test = append_to_tracking_table(master_table, mols_for_next_generation, 'generated', GLOBAL_GENERATION)\nmols_for_pd = new_mols_to_test[0]  # Extract the DataFrame of new molecules\nmols_for_export = new_mols_to_test[1]  # Extract the list of molecules for export\n\n# Append the new molecules DataFrame to the master table\nmaster_table = master_table.append(mols_for_pd)\nmaster_table = master_table.reset_index(drop=True)  # Reset the index\n# Save the updated master table to a CSV file for future reference\nmaster_table.to_csv(r'./master_results_table_gen' + str(GLOBAL_GENERATION) + '.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:38:27.197927Z","iopub.execute_input":"2024-02-20T00:38:27.198326Z","iopub.status.idle":"2024-02-20T00:38:28.026698Z","shell.execute_reply.started":"2024-02-20T00:38:27.198291Z","shell.execute_reply":"2024-02-20T00:38:28.025882Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"idAAAAgen3\nidAAABgen3\nidAAACgen3\nidAAADgen3\nidAAAEgen3\nidAAAFgen3\nidAAAGgen3\nidAAAHgen3\nidAAAIgen3\nidAAAJgen3\nidAAAKgen3\nidAAALgen3\nidAAAMgen3\nidAAANgen3\nidAAAOgen3\nidAAAPgen3\nidAAAQgen3\nidAAARgen3\nidAAASgen3\nidAAATgen3\nidAAAUgen3\nidAAAVgen3\nidAAAWgen3\nidAAAXgen3\nidAAAYgen3\nidAAAZgen3\nidAABAgen3\nidAABBgen3\nidAABCgen3\nidAABDgen3\nidAABEgen3\nidAABFgen3\nidAABGgen3\nidAABHgen3\nidAABIgen3\nidAABJgen3\nidAABKgen3\nidAABLgen3\nidAABMgen3\nidAABNgen3\nidAABOgen3\nidAABPgen3\nidAABQgen3\nidAABRgen3\nidAABSgen3\nidAABTgen3\nidAABUgen3\nidAABVgen3\nidAABWgen3\nidAABXgen3\nidAABYgen3\nidAABZgen3\nidAACAgen3\nidAACBgen3\nidAACCgen3\nidAACDgen3\nidAACEgen3\nidAACFgen3\nidAACGgen3\nidAACHgen3\nidAACIgen3\nidAACJgen3\nidAACKgen3\nidAACLgen3\nidAACMgen3\nidAACNgen3\nidAACOgen3\nidAACPgen3\nidAACQgen3\nidAACRgen3\nidAACSgen3\nidAACTgen3\nidAACUgen3\nidAACVgen3\nidAACWgen3\nidAACXgen3\nidAACYgen3\nidAACZgen3\nidAADAgen3\nidAADBgen3\nidAADCgen3\nidAADDgen3\nidAADEgen3\nidAADFgen3\nidAADGgen3\nidAADHgen3\nidAADIgen3\nidAADJgen3\nidAADKgen3\nidAADLgen3\nidAADMgen3\nidAADNgen3\nidAADOgen3\nidAADPgen3\nidAADQgen3\nidAADRgen3\nidAADSgen3\nidAADTgen3\nidAADUgen3\nidAADVgen3\nidAADWgen3\nidAADXgen3\nidAADYgen3\nidAADZgen3\nidAAEAgen3\nidAAEBgen3\nidAAECgen3\nidAAEDgen3\nidAAEEgen3\nidAAEFgen3\nidAAEGgen3\nidAAEHgen3\nidAAEIgen3\nidAAEJgen3\nidAAEKgen3\nidAAELgen3\nidAAEMgen3\nidAAENgen3\nidAAEOgen3\nidAAEPgen3\nidAAEQgen3\nidAAERgen3\nidAAESgen3\nidAAETgen3\nidAAEUgen3\nidAAEVgen3\nidAAEWgen3\nidAAEXgen3\nidAAEYgen3\nidAAEZgen3\nidAAFAgen3\nidAAFBgen3\nidAAFCgen3\nidAAFDgen3\nidAAFEgen3\nidAAFFgen3\nidAAFGgen3\nidAAFHgen3\nidAAFIgen3\nidAAFJgen3\nidAAFKgen3\nidAAFLgen3\nidAAFMgen3\nidAAFNgen3\nidAAFOgen3\nidAAFPgen3\nidAAFQgen3\nidAAFRgen3\nidAAFSgen3\nidAAFTgen3\nidAAFUgen3\nidAAFVgen3\nidAAFWgen3\nidAAFXgen3\nidAAFYgen3\nidAAFZgen3\nidAAGAgen3\nidAAGBgen3\nidAAGCgen3\nidAAGDgen3\nidAAGEgen3\nidAAGFgen3\nidAAGGgen3\nidAAGHgen3\nidAAGIgen3\nidAAGJgen3\nidAAGKgen3\nidAAGLgen3\nidAAGMgen3\nidAAGNgen3\nidAAGOgen3\nidAAGPgen3\nidAAGQgen3\nidAAGRgen3\nidAAGSgen3\nidAAGTgen3\nidAAGUgen3\nidAAGVgen3\nidAAGWgen3\nidAAGXgen3\nidAAGYgen3\nidAAGZgen3\nidAAHAgen3\nidAAHBgen3\nidAAHCgen3\nidAAHDgen3\nidAAHEgen3\nidAAHFgen3\nidAAHGgen3\nidAAHHgen3\nidAAHIgen3\nidAAHJgen3\nidAAHKgen3\nidAAHLgen3\nidAAHMgen3\nidAAHNgen3\nidAAHOgen3\nidAAHPgen3\nidAAHQgen3\nidAAHRgen3\nidAAHSgen3\nidAAHTgen3\nidAAHUgen3\nidAAHVgen3\nidAAHWgen3\nidAAHXgen3\nidAAHYgen3\nidAAHZgen3\nidAAIAgen3\nidAAIBgen3\nidAAICgen3\nidAAIDgen3\nidAAIEgen3\nidAAIFgen3\nidAAIGgen3\nidAAIHgen3\nidAAIIgen3\nidAAIJgen3\nidAAIKgen3\nidAAILgen3\nidAAIMgen3\nidAAINgen3\nidAAIOgen3\nidAAIPgen3\nidAAIQgen3\nidAAIRgen3\nidAAISgen3\nidAAITgen3\nidAAIUgen3\nidAAIVgen3\nidAAIWgen3\nidAAIXgen3\nidAAIYgen3\nidAAIZgen3\nidAAJAgen3\nidAAJBgen3\nidAAJCgen3\nidAAJDgen3\nidAAJEgen3\nidAAJFgen3\nidAAJGgen3\nidAAJHgen3\nidAAJIgen3\nidAAJJgen3\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming mols_for_export has been assigned a value\nprint(len(mols_for_export))","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:39:32.800737Z","iopub.execute_input":"2024-02-20T00:39:32.801259Z","iopub.status.idle":"2024-02-20T00:39:32.805922Z","shell.execute_reply.started":"2024-02-20T00:39:32.801217Z","shell.execute_reply":"2024-02-20T00:39:32.805057Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"244\n","output_type":"stream"}]},{"cell_type":"code","source":"def write_gen_to_sdf(mols_for_export, generation, batch_size):\n    # Check if the number of molecules exceeds the batch size\n    if len(mols_for_export) > batch_size:\n        # Calculate the number of batches needed\n        batches = (len(mols_for_export) // batch_size) + 1\n        # Iterate over each batch\n        for i in range(batches):\n            # Extract the current batch of molecules\n            batch_to_export = mols_for_export[i * batch_size:(i + 1) * batch_size]\n            # Create an SDF writer for the current batch\n            w = Chem.SDWriter('gen' + str(generation) + '_batch_' + str(i + 1) + '.sdf')\n            # Write each molecule in the batch to the SDF file\n            for m in batch_to_export:\n                w.write(m)\n    else:\n        # If the number of molecules does not exceed the batch size, write them to a single SDF file\n        w = Chem.SDWriter('gen' + str(generation) + '.sdf')\n        for m in mols_for_export:\n            w.write(m)\n    \n    # Ensure the last molecule is written correctly by writing it to an arbitrary SDF file\n    w = Chem.SDWriter('test.sdf')\n    w.write(mols_for_export[-1])\n    \n    return mols_for_export","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:40:49.315161Z","iopub.execute_input":"2024-02-20T00:40:49.315528Z","iopub.status.idle":"2024-02-20T00:40:49.323148Z","shell.execute_reply.started":"2024-02-20T00:40:49.315494Z","shell.execute_reply":"2024-02-20T00:40:49.322122Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"write_gen_to_sdf(mols_for_export, GLOBAL_GENERATION, 2000)  # Export the generated molecules to SDF files\nprint('ok')  # Print 'ok' to indicate that the export process is complete","metadata":{"execution":{"iopub.status.busy":"2024-02-20T00:41:06.090917Z","iopub.execute_input":"2024-02-20T00:41:06.091300Z","iopub.status.idle":"2024-02-20T00:41:06.233697Z","shell.execute_reply.started":"2024-02-20T00:41:06.091263Z","shell.execute_reply":"2024-02-20T00:41:06.232766Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}